{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read unzipped CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# codes for each file-type and list of years used\n",
    "\n",
    "filecodes = ['B02001', 'S0101', 'S1401', 'S1501', 'S1601', 'S1901',\n",
    "             'S1902', 'S1903', 'S2001', 'S2101', 'S2201', 'S2301']\n",
    "\n",
    "years = [12, 13, 14, 15, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reader(filecodes, years):\n",
    "    \n",
    "    '''\n",
    "    read all the csv's to their own dataframes\n",
    "    \n",
    "    return a list of n*m dataframes... wow\n",
    "    '''\n",
    "    \n",
    "    df_list = []\n",
    "    \n",
    "    for year in years:\n",
    "                \n",
    "        for filecode in filecodes:\n",
    "            \n",
    "            df_list.append(\n",
    "                pd.read_csv(\n",
    "                '/home/nate/ds/metis/class_work/projects/raw_data/acs{}/ACS_{}_1YR_{}_with_ann.csv'\n",
    "                .format(year, year, filecode)))\n",
    "        \n",
    "            \n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of all 60 dataframes and check len\n",
    "\n",
    "df_list = reader(filecodes, years)\n",
    "\n",
    "len(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean-up Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remake_ids(df_list):\n",
    "    \n",
    "    '''\n",
    "    all dataframes start with col_names in zero-th row and two id cols \n",
    "    \n",
    "    remove these\n",
    "    '''\n",
    "    \n",
    "    no_ids = []\n",
    "\n",
    "    for df in df_list:\n",
    "\n",
    "        df.columns = df.iloc[0]\n",
    "\n",
    "        df = df.drop(0).reset_index()\n",
    "\n",
    "        df = df.drop(df.columns[0:3], axis=1)\n",
    "        \n",
    "        no_ids.append(df)\n",
    "        \n",
    "    return no_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_ids = remake_ids(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean-up by Filecodes and Re-name Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_cleaner(df_list):\n",
    "    \n",
    "    '''\n",
    "    takes the list of df's\n",
    "    \n",
    "    9 per year, 5 years, down to 45 from 60\n",
    "    \n",
    "    cleans according to filetype, returns list of clean dfs\n",
    "    \n",
    "    PRE-MVP: down to 25 dfs, 5 per year, single variable per df\n",
    "    '''\n",
    "    \n",
    "    clean_dfs = []\n",
    "    \n",
    "    for i, df in enumerate(df_list):\n",
    "        \n",
    "        # for 0 (race)\n",
    "###### just white ratio for now, come back after MVP\n",
    "        if i%12==0:\n",
    "            df = df.drop(df.columns[2::2], axis=1)\n",
    "            df = df.drop(df.columns[9:], axis=1)\n",
    "#             df.columns = ['geo', 'total', 'white', 'black', 'american_indian',\n",
    "#                           'asian', 'native_hawaiian', 'two_plus']\n",
    "            df = df.drop(df.columns[3:], axis=1)\n",
    "            x = []\n",
    "            j=0\n",
    "            for row in df.iterrows():\n",
    "                x.append(float(df.iloc[j][2]) / (float(df.iloc[j][1])))\n",
    "                j+=1\n",
    "            x = pd.Series(x)   \n",
    "            df = df[['Geography']]\n",
    "            df['white_ratio'] = x\n",
    "            df.columns = ['geography', 'white_ratio']        \n",
    "            clean_dfs.append(df)\n",
    "            \n",
    "        # for 1 (age+sex)\n",
    "###### just sex for now, come back after MVP\n",
    "        elif i%12==1:\n",
    "            df = df[['Geography', 'Male; Estimate; Total population', 'Female; Estimate; Total population']]\n",
    "#             df = df.drop(df.columns[2::2], axis=1)\n",
    "#             df = df.drop(df.columns[5::3], axis=1)\n",
    "#             df = df.drop(df.columns[5::2], axis=1)\n",
    "#             df = df.drop(df.columns[22:], axis=1)\n",
    "            x = []\n",
    "            j=0\n",
    "            for row in df.iterrows():\n",
    "                x.append(float(df.iloc[j][2]) / (float(df.iloc[j][1]) + float(df.iloc[j][2])))\n",
    "                j+=1\n",
    "            x = pd.Series(x)   \n",
    "            df = df[['Geography']]\n",
    "            df['female_ratio'] = x\n",
    "            df.columns = ['geography', 'female_ratio']\n",
    "            clean_dfs.append(df)\n",
    "            \n",
    "        # for 2 (school enrollment)\n",
    "###### come back after MVP\n",
    "        elif i%12==2:\n",
    "            pass\n",
    "#             cols = [col for col in df.columns if col[:24] == 'Total; Estimate; Percent']\n",
    "#             df = pd.concat([df['Geography'], df[cols]], axis=1)\n",
    "        \n",
    "        # for 3 (highest education)\n",
    "        elif i%12==3:\n",
    "            try:\n",
    "                df = df[['Geography', \"Total; Estimate; Associate's degree\", \n",
    "                         \"Total; Estimate; Bachelor's degree\", \"Total; Estimate; Graduate or professional degree\"]]\n",
    "            except:\n",
    "                df = df[['Geography', \"Total; Estimate; Population 25 years and over - Associate's degree\",\n",
    "                         \"Total; Estimate; Population 25 years and over - Bachelor's degree\",\n",
    "                         'Total; Estimate; Population 25 years and over - Graduate or professional degree']]\n",
    "            x = []\n",
    "            j=0\n",
    "            for row in df.iterrows():\n",
    "                x.append(float(df.iloc[j][1]) + float(df.iloc[j][2]) + float(df.iloc[j][3]))\n",
    "                j+=1\n",
    "            x = pd.Series(x)   \n",
    "            df = df[['Geography']]\n",
    "            df['college_ratio'] = x\n",
    "            df.columns = ['geography', 'college_ratio']\n",
    "            clean_dfs.append(df)\n",
    "            \n",
    "        # for 4 (home lang)\n",
    "        elif i%12==4:\n",
    "            df = df[['Geography', 'Total; Estimate; Speak only English']]\n",
    "            df.columns = ['geography', 'eng_ratio']\n",
    "            clean_dfs.append(df)\n",
    "            \n",
    "        # for 5 (Income)\n",
    "###### come back after MVP                         \n",
    "        # info for i%12== 6, 7, 8 was found in i%12==5    \n",
    "        elif i%12==5:\n",
    "            pass\n",
    "#             df = df.drop(df.columns[2::2], axis=1)\n",
    "#             df = df.drop(df.columns[53:], axis=1)\n",
    "            \n",
    "        elif i%12==6:\n",
    "            pass\n",
    "        elif i%12==7:\n",
    "            pass\n",
    "        elif i%12==8:\n",
    "            pass\n",
    "            \n",
    "        # for 9 (veteran status)\n",
    "####### come back after MVP\n",
    "        elif i%12==9:\n",
    "            pass\n",
    "#             df = df[['Geography', 'Total; Estimate; Civilian population 18 years and over',\n",
    "#                      'Veterans; Estimate; Civilian population 18 years and over']]\n",
    "#             x = []\n",
    "#             m=0\n",
    "#             for row in df.iterrows():\n",
    "#                 x.append(float(df.iloc[m][2]) / float(df.iloc[m][1]))\n",
    "#                 m+=1\n",
    "#             x = pd.Series(x)   \n",
    "#             df = df[['Geography']]\n",
    "#             df['veteran_ratio'] = x\n",
    "#             df.columns = ['geography', 'veteran_ratio']\n",
    "            \n",
    "        # for 10 (food stamps)\n",
    "###### come back after MVP\n",
    "        elif i%12==10:  \n",
    "            pass\n",
    "#             try:\n",
    "#                 df = df[['Geography', 'Total; Estimate; Households',\n",
    "#                          'Households receiving food stamps; Estimate; Households']]\n",
    "#             except:\n",
    "#                 df = df[['Geography', 'Total; Estimate; Households',\n",
    "#                          'Households receiving food stamps/SNAP; Estimate; Households']]\n",
    "#             x = []\n",
    "#             n=0\n",
    "#             for row in df.iterrows():\n",
    "#                 x.append(float(df.iloc[n][1]) / float(df.iloc[n][2]))\n",
    "#                 n+=1\n",
    "#             x = pd.Series(x)   \n",
    "#             df = df[['Geography']]\n",
    "#             df['food_stamps'] = x\n",
    "#             df.columns = ['geography', 'food_stamps']\n",
    "            \n",
    "        # for 11 (employment status)    \n",
    "        else:\n",
    "            df = df[['Geography', 'Unemployment rate; Estimate; Population 16 years and over']]\n",
    "            df.columns = ['geography', 'unemployment']\n",
    "            clean_dfs.append(df)\n",
    "        \n",
    "    return clean_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_dfs = file_cleaner(no_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat dfs by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def years(df_list):\n",
    "    \n",
    "    '''\n",
    "    initialize 5 dfs, one for each year\n",
    "    \n",
    "    also add col with year\n",
    "    '''\n",
    "    \n",
    "    list_12 = []\n",
    "    list_13 = []\n",
    "    list_14 = []\n",
    "    list_15 = []\n",
    "    list_16 = []\n",
    "    \n",
    "    num_df = len(df_list)/5\n",
    "    \n",
    "    for i, df in enumerate(df_list):\n",
    "        \n",
    "        if i < num_df:\n",
    "            list_12.append(df)\n",
    "        \n",
    "        elif i < num_df*2:\n",
    "            list_13.append(df)\n",
    "            \n",
    "        elif i < num_df*3:\n",
    "            list_14.append(df)\n",
    "            \n",
    "        elif i < num_df*4:\n",
    "            list_15.append(df)\n",
    "            \n",
    "        elif i < num_df*5:\n",
    "            list_16.append(df)\n",
    "            \n",
    "    \n",
    "    df_12 = pd.concat([df for df in list_12], axis=1)\n",
    "    df_12 = df_12.T.drop_duplicates().T\n",
    "    df_12['year'] = 12\n",
    "    \n",
    "    df_13 = pd.concat([df for df in list_13], axis=1)\n",
    "    df_13 = df_13.T.drop_duplicates().T\n",
    "    df_13['year'] = 13\n",
    "    \n",
    "    df_14 = pd.concat([df for df in list_14], axis=1)\n",
    "    df_14 = df_14.T.drop_duplicates().T\n",
    "    df_14['year'] = 14\n",
    "    \n",
    "    df_15 = pd.concat([df for df in list_15], axis=1)\n",
    "    df_15 = df_15.T.drop_duplicates().T\n",
    "    df_15['year'] = 15\n",
    "    \n",
    "    df_16 = pd.concat([df for df in list_16], axis=1)\n",
    "    df_16 = df_16.T.drop_duplicates().T\n",
    "    df_16['year'] = 16\n",
    "    \n",
    "            \n",
    "    return df_12, df_13, df_14, df_15, df_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_12, df_13, df_14, df_15, df_16 = years(clean_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_12.to_csv('/home/nate/ds/metis/class_work/projects/clean_data/df_12.csv')\n",
    "df_13.to_csv('/home/nate/ds/metis/class_work/projects/clean_data/df_13.csv')\n",
    "df_14.to_csv('/home/nate/ds/metis/class_work/projects/clean_data/df_14.csv')\n",
    "df_15.to_csv('/home/nate/ds/metis/class_work/projects/clean_data/df_15.csv')\n",
    "df_16.to_csv('/home/nate/ds/metis/class_work/projects/clean_data/df_16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
