{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read unzipped CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# codes for each file-type and list of years used\n",
    "\n",
    "filecodes = ['B02001', 'S0101', 'S1401', 'S1501', 'S1601', 'S1901',\n",
    "             'S1902', 'S1903', 'S2001', 'S2101', 'S2201', 'S2301']\n",
    "\n",
    "years = [12, 13, 14, 15, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reader(filecodes, years):\n",
    "    \n",
    "    '''\n",
    "    read all the csv's to their own dataframes\n",
    "    \n",
    "    return a list of n*m dataframes... wow\n",
    "    '''\n",
    "    \n",
    "    df_list = []\n",
    "    \n",
    "    for year in years:\n",
    "                \n",
    "        for filecode in filecodes:\n",
    "            \n",
    "            df_list.append(\n",
    "                pd.read_csv(\n",
    "                '/home/nate/ds/metis/class_work/projects/raw_data/acs{}/ACS_{}_1YR_{}_with_ann.csv'\n",
    "                .format(year, year, filecode)))\n",
    "        \n",
    "            \n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of all 60 dataframes and check len\n",
    "\n",
    "df_list = reader(filecodes, years)\n",
    "\n",
    "len(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean-up Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remake_ids(df_list):\n",
    "    \n",
    "    '''\n",
    "    all dataframes start with col_names in zero-th row and two id cols \n",
    "    \n",
    "    remove these\n",
    "    '''\n",
    "    \n",
    "    no_ids = []\n",
    "\n",
    "    for df in df_list:\n",
    "\n",
    "        df.columns = df.iloc[0]\n",
    "\n",
    "        df = df.drop(0).reset_index()\n",
    "\n",
    "        df = df.drop(df.columns[0:3], axis=1)\n",
    "        \n",
    "        no_ids.append(df)\n",
    "        \n",
    "    return no_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_ids = remake_ids(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# no_ids[39]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean-up by Filecodes and Re-name Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_cleaner(df_list):\n",
    "    \n",
    "    '''\n",
    "    takes the list of df's\n",
    "    \n",
    "    9 per year, 5 years, down to 45 from 60\n",
    "    \n",
    "    cleans according to filetype, returns list of clean dfs\n",
    "    \n",
    "    PRE-MVP: down to 25 dfs, 5 per year, single variable per df\n",
    "    '''\n",
    "    \n",
    "    clean_dfs = []\n",
    "    \n",
    "    for i, df in enumerate(df_list):\n",
    "        \n",
    "        # for 0 (race)\n",
    "###### just white ratio for now, come back after MVP\n",
    "        if i%12==0:\n",
    "            df = df.drop(df.columns[2::2], axis=1)\n",
    "            df = df.drop(df.columns[9:], axis=1)\n",
    "#             df.columns = ['geo', 'total', 'white', 'black', 'american_indian',\n",
    "#                           'asian', 'native_hawaiian', 'two_plus']\n",
    "            df = df.drop(df.columns[3:], axis=1)\n",
    "            x = []\n",
    "            j=0\n",
    "            for row in df.iterrows():\n",
    "                x.append(float(df.iloc[j][2]) / (float(df.iloc[j][1])))\n",
    "                j+=1\n",
    "            x = pd.Series(x)   \n",
    "            df = df[['Geography']]\n",
    "            df['white_ratio'] = x\n",
    "            df.columns = ['geography', 'white_ratio']        \n",
    "            clean_dfs.append(df)\n",
    "            \n",
    "        # for 1 (age+sex)\n",
    "###### just sex for now, come back after MVP\n",
    "        elif i%12==1:\n",
    "            df = df[['Geography', 'Male; Estimate; Total population', 'Female; Estimate; Total population']]\n",
    "#             df = df.drop(df.columns[2::2], axis=1)\n",
    "#             df = df.drop(df.columns[5::3], axis=1)\n",
    "#             df = df.drop(df.columns[5::2], axis=1)\n",
    "#             df = df.drop(df.columns[22:], axis=1)\n",
    "            x = []\n",
    "            j=0\n",
    "            for row in df.iterrows():\n",
    "                x.append(float(df.iloc[j][2]) / (float(df.iloc[j][1]) + float(df.iloc[j][2])))\n",
    "                j+=1\n",
    "            x = pd.Series(x)   \n",
    "            df = df[['Geography']]\n",
    "            df['female_ratio'] = x\n",
    "            df.columns = ['geography', 'female_ratio']\n",
    "            clean_dfs.append(df)\n",
    "            \n",
    "        # for 2 (school enrollment)\n",
    "###### come back after MVP\n",
    "        elif i%12==2:\n",
    "            pass\n",
    "#             cols = [col for col in df.columns if col[:24] == 'Total; Estimate; Percent']\n",
    "#             df = pd.concat([df['Geography'], df[cols]], axis=1)\n",
    "        \n",
    "        # for 3 (highest education)\n",
    "        elif i%12==3:\n",
    "            if i < 38:\n",
    "                try:\n",
    "                    df = df[['Geography', \"Total; Estimate; Associate's degree\", \n",
    "                             \"Total; Estimate; Bachelor's degree\", \"Total; Estimate; Graduate or professional degree\"]]\n",
    "                    x = []\n",
    "                    j=0\n",
    "                    for row in df.iterrows():\n",
    "                        x.append((float(df.iloc[j][1]) + float(df.iloc[j][2]) + float(df.iloc[j][3]))/100)\n",
    "                        j+=1\n",
    "                    x = pd.Series(x)   \n",
    "                    df = df[['Geography']]\n",
    "                    df['college_ratio'] = x\n",
    "                    df.columns = ['geography', 'college_ratio']\n",
    "                    clean_dfs.append(df)\n",
    "                except:\n",
    "                    df = df[['Geography', 'Total; Estimate; Population 25 years and over',\n",
    "                             \"Total; Estimate; Population 25 years and over - Associate's degree\",\n",
    "                             \"Total; Estimate; Population 25 years and over - Bachelor's degree\",\n",
    "                             'Total; Estimate; Population 25 years and over - Graduate or professional degree']]\n",
    "                    x = []\n",
    "                    j=0\n",
    "                    for row in df.iterrows():\n",
    "                        x.append((float(df.iloc[j][2]) + float(df.iloc[j][3]) + float(df.iloc[j][4]))\n",
    "                                 /100)\n",
    "                        j+=1\n",
    "                    x = pd.Series(x)   \n",
    "                    df = df[['Geography']]\n",
    "                    df['college_ratio'] = x\n",
    "                    df.columns = ['geography', 'college_ratio']\n",
    "                    clean_dfs.append(df)\n",
    "            else:\n",
    "                df = df[['Geography', 'Total; Estimate; Population 25 years and over',\n",
    "                         \"Total; Estimate; Population 25 years and over - Associate's degree\",\n",
    "                         \"Total; Estimate; Population 25 years and over - Bachelor's degree\",\n",
    "                         'Total; Estimate; Population 25 years and over - Graduate or professional degree']]\n",
    "                x = []\n",
    "                j=0\n",
    "                for row in df.iterrows():\n",
    "                    x.append((float(df.iloc[j][2]) + float(df.iloc[j][3]) + float(df.iloc[j][4]))\n",
    "                             /(float(df.iloc[j][1])))\n",
    "                    j+=1\n",
    "                x = pd.Series(x)   \n",
    "                df = df[['Geography']]\n",
    "                df['college_ratio'] = x\n",
    "                df.columns = ['geography', 'college_ratio']\n",
    "                clean_dfs.append(df)\n",
    "            \n",
    "        # for 4 (home lang)\n",
    "        elif i%12==4:\n",
    "            if i<40:\n",
    "                df = df[['Geography', 'Total; Estimate; Speak only English']]\n",
    "                eng = []\n",
    "                for i, row in df.iterrows():\n",
    "                    eng.append(float(df.iloc[i][1])/100)\n",
    "                df = df[['Geography']]\n",
    "                df['eng'] = eng\n",
    "                df.columns = ['geography', 'eng_ratio']\n",
    "                clean_dfs.append(df)\n",
    "            else:\n",
    "                df = df[['Geography', 'Total; Estimate; Population 5 years and over',\n",
    "                         'Total; Estimate; Speak only English']]\n",
    "                eng = []\n",
    "                for i, row in df.iterrows():\n",
    "                    eng.append(float(df.iloc[i][2])/float(df.iloc[i][1]))\n",
    "                df = df[['Geography']]\n",
    "                df['eng'] = eng\n",
    "                df.columns = ['geography', 'eng_ratio']\n",
    "                clean_dfs.append(df)\n",
    "            \n",
    "        # for 5 (Income)\n",
    "###### come back after MVP                         \n",
    "        # info for i%12== 6, 7, 8 was found in i%12==5    \n",
    "        elif i%12==5:\n",
    "            df = df.drop(df.columns[2::2], axis=1)\n",
    "            df = df.drop(df.columns[53:], axis=1)\n",
    "            df = df.drop(df.columns[1:45], axis=1)\n",
    "            df = df.drop(df.columns[5:], axis=1)\n",
    "            df.columns = ['geography', 'household_median', 'family_median', 'married_median', 'nonfamily_median']\n",
    "            clean_dfs.append(df)\n",
    "            \n",
    "        elif i%12==6:\n",
    "            pass\n",
    "        elif i%12==7:\n",
    "            pass\n",
    "        elif i%12==8:\n",
    "            pass\n",
    "            \n",
    "        # for 9 (veteran status)\n",
    "####### come back after MVP\n",
    "        elif i%12==9:\n",
    "#             pass\n",
    "            df = df[['Geography', 'Total; Estimate; Civilian population 18 years and over',\n",
    "                     'Veterans; Estimate; Civilian population 18 years and over']]\n",
    "            x = []\n",
    "            m=0\n",
    "            for row in df.iterrows():\n",
    "                x.append(float(df.iloc[m][2]) / float(df.iloc[m][1]))\n",
    "                m+=1\n",
    "            x = pd.Series(x)   \n",
    "            df = df[['Geography']]\n",
    "            df['veteran_ratio'] = x\n",
    "            df.columns = ['geography', 'veteran_ratio']\n",
    "            clean_dfs.append(df)\n",
    "            \n",
    "        # for 10 (food stamps)\n",
    "###### come back after MVP\n",
    "        elif i%12==10:  \n",
    "            pass\n",
    "#             try:\n",
    "#                 df = df[['Geography', 'Total; Estimate; Households',\n",
    "#                          'Households receiving food stamps; Estimate; Households']]\n",
    "#             except:\n",
    "#                 df = df[['Geography', 'Total; Estimate; Households',\n",
    "#                          'Households receiving food stamps/SNAP; Estimate; Households']]\n",
    "#             x = []\n",
    "#             n=0\n",
    "#             for row in df.iterrows():\n",
    "#                 x.append(float(df.iloc[n][1]) / float(df.iloc[n][2]))\n",
    "#                 n+=1\n",
    "#             x = pd.Series(x)   \n",
    "#             df = df[['Geography']]\n",
    "#             df['food_stamps'] = x\n",
    "#             df.columns = ['geography', 'food_stamps']\n",
    "            \n",
    "        # for 11 (employment status)    \n",
    "        else:\n",
    "            df = df[['Geography', 'Unemployment rate; Estimate; Population 16 years and over']]\n",
    "            emp = []\n",
    "            for i, row in df.iterrows():\n",
    "                emp.append(float(df.iloc[i][1])/100)\n",
    "            df = df[['Geography']]\n",
    "            df['emp'] = emp\n",
    "            df.columns = ['geography', 'unemployment']\n",
    "            clean_dfs.append(df)\n",
    "        \n",
    "    return clean_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_dfs = file_cleaner(no_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat dfs by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def years(df_list):\n",
    "    \n",
    "    '''\n",
    "    initialize 5 dfs, one for each year\n",
    "    \n",
    "    also add col with year\n",
    "    '''\n",
    "    \n",
    "    list_12 = []\n",
    "    list_13 = []\n",
    "    list_14 = []\n",
    "    list_15 = []\n",
    "    list_16 = []\n",
    "    \n",
    "    num_df = len(df_list)/5\n",
    "    \n",
    "    for i, df in enumerate(df_list):\n",
    "        \n",
    "        if i < num_df:\n",
    "            list_12.append(df)\n",
    "        \n",
    "        elif i < num_df*2:\n",
    "            list_13.append(df)\n",
    "            \n",
    "        elif i < num_df*3:\n",
    "            list_14.append(df)\n",
    "            \n",
    "        elif i < num_df*4:\n",
    "            list_15.append(df)\n",
    "            \n",
    "        elif i < num_df*5:\n",
    "            list_16.append(df)\n",
    "            \n",
    "    \n",
    "    df_12 = pd.concat([df for df in list_12], axis=1)\n",
    "    df_12 = df_12.T.drop_duplicates().T\n",
    "    df_12['year'] = 12\n",
    "    \n",
    "    df_13 = pd.concat([df for df in list_13], axis=1)\n",
    "    df_13 = df_13.T.drop_duplicates().T\n",
    "    df_13['year'] = 13\n",
    "    \n",
    "    df_14 = pd.concat([df for df in list_14], axis=1)\n",
    "    df_14 = df_14.T.drop_duplicates().T\n",
    "    df_14['year'] = 14\n",
    "    \n",
    "    df_15 = pd.concat([df for df in list_15], axis=1)\n",
    "    df_15 = df_15.T.drop_duplicates().T\n",
    "    df_15['year'] = 15\n",
    "    \n",
    "    df_16 = pd.concat([df for df in list_16], axis=1)\n",
    "    df_16 = df_16.T.drop_duplicates().T\n",
    "    df_16['year'] = 16\n",
    "    \n",
    "            \n",
    "    return df_12, df_13, df_14, df_15, df_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_12, df_13, df_14, df_15, df_16 = years(clean_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Make Legal Col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recreationally legal\n",
    "\n",
    "rec_12 = ['Colorado', 'Washington']\n",
    "rec_13 = ['Colorado', 'Washington']\n",
    "rec_14 = ['Alaska', 'Colorado', 'District of Columbia', 'Oregon', 'Washington']\n",
    "rec_15 = ['Alaska', 'Colorado', 'District of Columbia', 'Oregon', 'Washington']\n",
    "rec_16 = ['Alaska', 'California', 'Colorado', 'District of Columbia',\n",
    "             'Nevada', 'Maine', 'Massachusetts', 'Oregon', 'Washington']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# medicinally legal\n",
    "\n",
    "med_12 = ['California', 'Alaska', 'Oregon', 'Washington', 'Maine', 'Colorado', 'Hawaii', 'Nevada',\n",
    "          'Montana', 'Vermont', 'Rhode Island', 'New Mexico', 'Michigan', 'Arizona', 'District of Columbia',\n",
    "          'New Jersey', 'Delaware', 'Connecticut', 'Massachusetts']\n",
    "med_13 = ['California', 'Alaska', 'Oregon', 'Washington', 'Maine', 'Colorado', 'Hawaii', 'Nevada',\n",
    "          'Montana', 'Vermont', 'Rhode Island', 'New Mexico', 'Michigan', 'Arizona', 'District of Columbia',\n",
    "          'New Jersey', 'Delaware', 'Connecticut', 'Massachusetts', 'Illinois', 'New Hampshire']\n",
    "med_14 = ['California', 'Alaska', 'Oregon', 'Washington', 'Maine', 'Colorado', 'Hawaii', 'Nevada',\n",
    "          'Montana', 'Vermont', 'Rhode Island', 'New Mexico', 'Michigan', 'Arizona', 'District of Columbia',\n",
    "          'New Jersey', 'Delaware', 'Connecticut', 'Massachusetts', 'Illinois', 'New Hampshire', 'Maryland',\n",
    "          'Minnesota', 'New York']\n",
    "med_15 = ['California', 'Alaska', 'Oregon', 'Washington', 'Maine', 'Colorado', 'Hawaii', 'Nevada',\n",
    "          'Montana', 'Vermont', 'Rhode Island', 'New Mexico', 'Michigan', 'Arizona', 'District of Columbia',\n",
    "          'New Jersey', 'Delaware', 'Connecticut', 'Massachusetts', 'Illinois', 'New Hampshire', 'Maryland',\n",
    "          'Minnesota', 'New York', 'Louisiana']\n",
    "med_16 = ['California', 'Alaska', 'Oregon', 'Washington', 'Maine', 'Colorado', 'Hawaii', 'Nevada',\n",
    "          'Montana', 'Vermont', 'Rhode Island', 'New Mexico', 'Michigan', 'Arizona', 'District of Columbia',\n",
    "          'New Jersey', 'Delaware', 'Connecticut', 'Massachusetts', 'Illinois', 'New Hampshire', 'Maryland',\n",
    "          'Minnesota', 'New York', 'Louisiana', 'Ohio', 'Pensylvania', 'Florida', 'North Dakota', 'Arkansas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rec_legal(df, states):\n",
    "    \n",
    "    '''\n",
    "    make col for legal based on list of states\n",
    "    \n",
    "    drop puerto rico and us aggregate\n",
    "    '''\n",
    "    \n",
    "#     df = df.drop(df.columns[0], axis=1)\n",
    "    df = df.drop(0)\n",
    "    df = df.drop(52)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    rec_legal = np.zeros((51,1))\n",
    "    df['rec_legal'] = rec_legal\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if df.iloc[index][0] in states:\n",
    "            df.at[index, 'rec_legal'] = 1.0\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def med_legal(df, states):\n",
    "    \n",
    "    '''\n",
    "    make col for legal based on list of states\n",
    "    \n",
    "    drop puerto rico and us aggregate\n",
    "    '''\n",
    "    \n",
    "    med_legal = np.zeros((51,1))\n",
    "    df['med_legal'] = med_legal\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if df.iloc[index][0] in states:\n",
    "            df.at[index, 'med_legal'] = 1.0\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_12 = rec_legal(df_12, rec_12)\n",
    "df_13 = rec_legal(df_13, rec_13)\n",
    "df_14 = rec_legal(df_14, rec_14)\n",
    "df_15 = rec_legal(df_15, rec_15)\n",
    "df_16 = rec_legal(df_16, rec_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_12 = med_legal(df_12, med_12)\n",
    "df_13 = med_legal(df_13, med_13)\n",
    "df_14 = med_legal(df_14, med_14)\n",
    "df_15 = med_legal(df_15, med_15)\n",
    "df_16 = med_legal(df_16, med_16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_12.to_csv('/home/nate/ds/metis/class_work/projects/clean_data/df_12.csv')\n",
    "df_13.to_csv('/home/nate/ds/metis/class_work/projects/clean_data/df_13.csv')\n",
    "df_14.to_csv('/home/nate/ds/metis/class_work/projects/clean_data/df_14.csv')\n",
    "df_15.to_csv('/home/nate/ds/metis/class_work/projects/clean_data/df_15.csv')\n",
    "df_16.to_csv('/home/nate/ds/metis/class_work/projects/clean_data/df_16.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Store in PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnx = create_engine('postgresql://ubuntu:metis123@18.219.101.103:5432')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_12.to_sql('DF12', cnx, if_exists='replace', index=False)\n",
    "df_13.to_sql('DF13', cnx, if_exists='replace', index=False)\n",
    "df_14.to_sql('DF14', cnx, if_exists='replace', index=False)\n",
    "df_15.to_sql('DF15', cnx, if_exists='replace', index=False)\n",
    "df_16.to_sql('DF16', cnx, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
